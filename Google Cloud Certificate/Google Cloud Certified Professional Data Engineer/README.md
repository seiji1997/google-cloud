# Google Cloud Certified Professional Data Engineer

Professional Data Engineer enable data-driven decision making by collecting, transforming, and publishing data. A Data Engineer should be able to design, build, operationalize, secure, and monitor data processing systems with a particular emphasis on security and portability. A Data Engineer should also to leverage, deploy, and continuously train pre-existing machine learning models.

The Professional Data Engineer exam assesses your ability to:

- Design data processing systems
- Ensure solution quality
- Operationalize machine learning models
- Build and Operationalize data processing systems

contents
- **Section 1. Designing data processing systems**
- **Section 2. Building and operationalizing data processing systems**
- **Section 3. Operationalizing machine learning models**
- **Section 4. Ensuring solution quality**

# MUST LEARNING

クラスタ化とパーティショニングによるクエリの費用削減

[https://cloud.google.com/bigquery/docs/best-practices-costs#use_clustered_or_partitioned_tables](https://cloud.google.com/bigquery/docs/best-practices-costs#use_clustered_or_partitioned_tables)

Dataflow

[https://docs.google.com/presentation/d/1JhYAl7fg1U9iXh5crUQwYH41MrGl3Oi0Ks6eY0XJtTU/edit#slide=id.g1402d4a1e47_0_189](https://docs.google.com/presentation/d/1JhYAl7fg1U9iXh5crUQwYH41MrGl3Oi0Ks6eY0XJtTU/edit#slide=id.g1402d4a1e47_0_189)

# V**ocabulary**

- [Apache SparkとHadoop](https://atmarkit.itmedia.co.jp/ait/articles/1608/24/news014.html)
- [SDK](https://www.notion.so/Google-Cloud-Certified-Professional-Data-Engineer-f4ff5fb02a1049e594318d258509b031)
- [フォールトトレランス](https://e-words.jp/w/フォールトトレランス.html)
- [ミッションクリティカル](https://www.notion.so/Google-Cloud-Certified-Professional-Data-Engineer-f4ff5fb02a1049e594318d258509b031)
- [Apache Avro](https://engineering.mercari.com/blog/entry/2019-05-20-115839/)
- [kafka](https://cloud.google.com/learn/what-is-apache-kafka?hl=ja)
- [Redis](https://e-words.jp/w/Redis.html)
- [セグメント](https://www.notion.so/Google-Cloud-Certified-Professional-Data-Engineer-f4ff5fb02a1049e594318d258509b031)
- [Dataflow: Apache Beam のプログラミング モデル](https://cloud.google.com/dataflow/docs/concepts/beam-programming-model)
- [サイロ化](https://www.ntt.com/bizon/glossary/j-s/silo.html#:~:text=ビジネス／IT領域におけるサイロ,などが挙げられます。)
- [ANSI SQL](https://docs.oracle.com/cd/E57425_01/121/SQLRF/intro002.htm)
- [Dataprep by Trifacta](https://cloud.google.com/dataprep)
- [Cloud Composer](https://cloud.google.com/composer)
- [ガバナンスとコンプライアンス](https://www.dodadsj.com/content/200601_governance/)
- [Open DataBase Connectivity](https://e-words.jp/w/ODBC.html)
- [ACID](https://e-words.jp/w/ACID特性.html)
- [Hive](https://www.idcf.jp/words/hive.html)
- [デコミッション](https://e-words.jp/w/デコミッション.html#:~:text=デコミッション)

# **Coursera - Data Engineer**

why coursera?

Because of Effective to pass the exam.

**course (this course has 6 courses Japanese version)**

Preparing for Google Cloud Certification: Cloud Data Engineer Professional Certificate Japanese version

**[Google Cloud Big Data and Machine Learning Fundamentals 日本語版](https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp?specialization=gcp-data-engineering-jp)**

このコースでは、データから AI へのライフサイクルをサポートする Google Cloud のビッグデータと機械学習のプロダクトおよびサービスを紹介します。Google Cloud で Vertex AI を使用して、ビッグデータ パイプラインと機械学習モデルを構築するためのプロセス、課題、メリットについて説明します。

**[Modernizing Data Lakes and Data Warehouses with GCP 日本語版](https://www.coursera.org/learn/data-lakes-data-warehouses-gcp-jp?specialization=gcp-data-engineering-jp)**

すべてのデータ パイプラインには、データレイクとデータ ウェアハウスという 2 つの主要コンポーネントがあります。このコースでは、それぞれのストレージのユースケースに焦点を当て、Google Cloud Platform で利用可能なデータレイクおよびデータ ウェアハウスのソリューションを技術的に詳しく説明します。 また、データ エンジニアの役割や、適切なデータ パイプラインが事業運営にもたらすメリットについて述べ、クラウド環境でデータ エンジニアリングを行うべき理由を説明します。受講者は Qwiklabs を使用して、Google Cloud Platform のデータレイクとデータ ウェアハウスを実際に使ってみることができます。

**[Building Batch Data Pipelines on GCP 日本語版](https://www.coursera.org/learn/batch-data-pipelines-gcp-jp?specialization=gcp-data-engineering-jp)**

データ パイプラインは通常、Extract-Load（抽出、読み込み）、Extract-Load-Transform（抽出、読み込み、変換）、Extract-Transform-Load（抽出、変換、読み込み）のいずれかの方式に分類されます。このコースでは、どの方式をどのような場合にバッチデータに対して使用すべきかを説明します。また、Google Cloud Platform 上のデータ変換技術（BigQuery など）、Cloud Dataproc での Spark の実行、Cloud Data Fusion でのパイプライン グラフ、Cloud Dataflow によるサーバーレスのデータ処理についても取り上げます。Qwiklabs を使用して、Google Cloud Platform でデータ パイプライン コンポーネントを実際に構築できます。

**[Building Resilient Streaming Analytics Systems on GCP 日本語版](https://www.coursera.org/learn/streaming-analytics-systems-gcp-jp?specialization=gcp-data-engineering-jp)**

ストリーミングの活用によって事業運営に関する指標をリアルタイムで入手できるようになり、企業ではますますストリーミング データの処理が行われるようになっています。このコースでは、Google Cloud Platform でストリーミング データ パイプラインを構築する方法について説明します。受信したストリーミング データを処理するための Cloud Pub/Sub についても解説します。また、Cloud Dataflow を使用してストリーミング データに集計と変換を適用する方法と、処理済みレコードを BigQuery やCloud Bigtable に保存して分析する方法も取り上げます。Qwiklabs を使用して、Google Cloud Platform でストリーミング データ パイプライン コンポーネントを実際に構築することができます。

**[Smart Analytics, Machine Learning, and AI on GCP 日本語版](https://www.coursera.org/learn/smart-analytics-machine-learning-ai-gcp-jp?specialization=gcp-data-engineering-jp)**

機械学習をデータ パイプラインに組み込むことで、企業はデータから効率的に分析情報を抽出できるようになります。このコースでは、必要なカスタマイズの程度に応じて、Google Cloud Platform で機械学習をデータ パイプラインに組み込む方法をいくつか説明します。たとえば、ほとんどあるいはまったくカスタマイズが必要ない場合向けの AutoML、機械学習機能の大幅なカスタマイズが必要な場合向けの AI Platform Notebooks と BigQuery Machine Learning を紹介します。また、このコースでは、Kubeflow を使用して機械学習ソリューションを本稼働させる方法についても説明します。受講者は Qwiklabs を使用して、Google Cloud Platform での機械学習モデルの構築を実際に体験することができます。

**[Preparing for the Google Cloud Professional Data Engineer Exam 日本語版](https://www.coursera.org/learn/preparing-cloud-professional-data-engineer-exam-jp?specialization=gcp-data-engineering-jp)**

このコースでは、トップダウン アプローチを使ってすでに身に着けている知識とスキルを把握し、情報とスキルが不十分な分野を特定します。本コースを受講することにより、独自の対策計画を立てることができます。わかっていることとわからないことを明確にし、この職務を担当する際に必要なスキルの習得と向上にお役立てください。

## **2022/8/1,2**
**week1** Learning Data Engineering and Building Data Lakes (total 2 h video)

- Learning Data Engineering (1h video, lab(analysis using BigQuery), test(about Data Engineering))
- Building Data Lakes (1h video, lab(loading taxi data in Cloud SQL), test(Building Data Lakes))

**week2** Building DWH (total 1.5h video)

- Building DWH (video, lab(loading data in BigQuery))
- BigQuery as Data warehousing solution(video, lab(treating JSON and array data by BigQuery))
- Partitioning and Clustering by BigQuery(test(Building DWH))

## 2022/8/3

**week1** Processing Streaming Data and Using Pub/Sub

- Overview of Processing Streaming Data (a few video, test(Overview of Processing Streaming Data))
- Serverless messaging using Cloud Pub/Sub(0.5h video, lab(publishing streaming data to Pub/Sub), test(Serverless massaging using pub/Sub))
- Streaming Functions of Cloud Dataflow(video 40 min, lab(Streaming Data Pipeline), test(Streaming Functions of Cloud Dataflow))

**week2** BigQuery and Bigtable

Streaming Functions of highly Throughput using BigQuery and Bigtable(total 1h video)

- Streaming to BigQuery (lab(Streaming analytics and dashboard), test((Streaming analytics and dashboard)))
- Streaming to Cloud Bigtable(20 min video, lab(Streaming Data pipeline to Bigtable), test(highly throughput streaming using Cloud Bigtable))

Highly Functions and Performance of BigQuery(total 45 min video)

- Highly Functions of BigQuery(a few video, lab((Performance Optimization with SQL of BigQuery) and (Make a Date Partition table by BigQuery)))

## **2022/8/3**
week1 (Data and Machine Learning on GCP Specialized course, total 7 min video)

- lab(Search open resource dataset of BigQuery), test(review of module)

week2 (BigData and Machine Learning on Google Cloud, total 31 min video)

- lab(Using open house data with BigQuery), test(BigData and Machine Learning)
- lab(recommend product Using Cloud SQL and Spark ML)

week3(BigData with BigQuery, total video 37min)

- lab(predict purchase of visitor with BigQuery)

week4(Options for Machine Learning on Google Cloud, total 24 min video)

- lab(Make a streaming data pipeline for real time dashboard Using Cloud Dataflow)

week5(Machine Learning workflow for VertexAI)

- lab(Predict loan risk using AutoML, total 25 min video)
- lab(Classification of picture by pre-build ML model using Cloud Vision API)

week6(summary, 3 min video)

## **2022/8/4**
- Well Come Professional Data Engineer Exam(18 min video, 40 min text, test 3 Questions)
- Design of Data Processing Systems(39 min video, 20 min text, pre-exam1)
- Design of Data Processing Systems and Operationalization(16 min video, 30 min text, pre-exam2, lab(challenge))
- Operationalization of Machine Learning Model(44 min video, 40 min text, pre-exam3, lab)
- Ensuring Solution Quality(16 min video, 20 min text, Testing for Measures related to reliability, policy and security)
- Release and Next Step(5 min video, 20 min text, for exam)

## **2022/8/5**
week1

- Overview of Analytics and AI(18 min video, test(overview of analytics and AI))
- Pre-build of ML model API for Unstructured Data(9 min video, lab(Unstructured Text Classification using Natural Language API))
- BigData Analytics using Cloud AI Platform Notebooks(6 min video, test(BigData analytics using Cloud AI Platform Notebooks))

week2

- Full operation of Custom ML model(14 min video, lab(execute AI model by Kubeflow))
- Build a custom model using SQL on BigQuery ML(14 min video, lab(predict Bicycle Riding time using Regression model of BQML), lab(recommendation of movie by BigQuery ML), test(build custom model using SQL on BigQuery ML))
- Build a custom model using Cloud Auto ML(26 min video, test(build of custom model using Cloud AutoML))

## **2022/8/6**
week1 

- Overview Batch Data Pipeline(17 min video, test(EL, ELT, ETL))
- Execution of Spark on Cloud Dataproc(49 min video, lab(Execute Apache Spark Job on Cloud Dataproc), test(Execution of Spark on Cloud Dataproc))

week2

- Manage Data Pipeline by Cloud Data Fusion and Cloud Composer(total 44 min video)
- Cloud Data Fusion: lab(Build Pipeline graph and Execution by Cloud Data Fusion))
- Cloud Composer:lab(Overview of Cloud Composer)
- Serverless data processing by Cloud Dataflow(39 min video, lab(Build simple Dataflow pipeline))
- Aggregating by GroupByKey and Combine(lab(MapReduce by Cloud Dataflow) lab(Sub-input to the Pipeline), test(Data Processing by Cloud Dataflow))
